---
title: What's New
description: Latest updates and improvements across all Cortex packages
sidebar_position: 1
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# What's New

Track the latest features, improvements, and fixes across the entire Cortex ecosystem.

:::info Single Source of Truth
This is the complete changelog for all Cortex packages. Individual package CHANGELOG.md files have been consolidated here for easier tracking.
:::

<Tabs groupId="package-filter">
<TabItem value="all" label="All Packages" default>

## January 2026

### TypeScript SDK v0.29.0 Â· Jan 9, 2026

**Automatic Fact and Entity Graph Sync**

ğŸ”— Graph sync now automatic when `CORTEX_GRAPH_SYNC=true`  
ğŸ“Š Facts extracted via `remember()` automatically sync to graph  
ğŸ·ï¸ Entity nodes created with MENTIONS relationships  
âš ï¸ **Breaking:** `syncToGraph` option removed from all APIs

<details>
<summary>Show full details</summary>

#### Major Changes

**Automatic Graph Synchronization**

Graph database synchronization for facts and entities is now automatic when `CORTEX_GRAPH_SYNC=true`:

- Facts stored via `remember()`, `facts.store()`, or `facts.revise()` automatically sync to graph
- Entity nodes are created from `fact.entities` array
- MENTIONS relationships link Fact nodes to Entity nodes
- Predicate-based relationships (e.g., WORKS_AT, KNOWS) created from `fact.relations`
- SUPERSEDES relationships created when belief revision supersedes facts
- Graph sync is gated entirely by environment variable

**Breaking Change**

The `syncToGraph` option has been removed from all APIs:

```typescript
// Before (v0.28.x)
await cortex.facts.store(params, { syncToGraph: true });

// After (v0.29.0+) - automatic when CORTEX_GRAPH_SYNC=true
await cortex.facts.store(params);
```

APIs affected:
- `cortex.facts.store()`, `update()`, `delete()`
- `cortex.memory.remember()`, `forget()`, `delete()`
- `cortex.vector.store()`, `update()`, `delete()`
- `cortex.conversations.create()`, `addMessage()`, `delete()`
- `cortex.contexts.create()`, `update()`, `delete()`
- `cortex.memorySpaces.register()`

**Migration:** Remove `{ syncToGraph: true/false }` from all API calls. Set `CORTEX_GRAPH_SYNC=true` in your environment to enable graph sync.

#### Technical Details

- `BeliefRevisionService.executeDecision()` now calls `syncFactToGraph()` and `syncFactRelationships()` after all fact operations
- All layer APIs check `if (this.graphAdapter)` instead of `if (options?.syncToGraph && this.graphAdapter)`
- Graph sync is non-blocking - failures are logged but don't fail the main operation

</details>

---

### CLI v0.28.1 Â· Jan 6, 2026

**Automatic Shell Tab Completion**

âŒ¨ï¸ Auto-installs completions for zsh, bash, and fish shells  
âœ¨ Dynamic completion for deployment and app names  
ğŸ§¹ Clean removal on uninstall via preuninstall script

<details>
<summary>Show full details</summary>

#### Added

- **Automatic shell tab completion** - Tab completion auto-installs during `npm install -g @cortexmemory/cli`:
  - Completes all commands, subcommands, and options with descriptions
  - Dynamic completion of deployment and app names from `~/.cortexrc`
  - Completion scripts installed to `~/.cortex/completions/`
  - Source line added automatically to shell RC files (idempotent)
  - Clean removal via preuninstall script on `npm uninstall -g`
  - Manual fallback: `cortex completion <zsh|bash|fish>` outputs completion script

#### Changed

- Package version display now shows "Vercel AI" instead of "AI" for clarity in `cortex update` output

</details>

---

### TypeScript SDK v0.28.0 Â· Jan 5, 2026

**Basic Template & Query Performance Fixes**

ğŸ¯ New headless template with dual CLI/server modes  
âš¡ Fixed "too many bytes" error in stats queries  
ğŸ§ª Complete test suite with E2E coverage

<details>
<summary>Show full details</summary>

#### New Basic Template

Complete headless demo of Cortex Memory SDK with both CLI and HTTP server modes:

- **Dual-mode operation** - Interactive CLI (`npm start`) or REST API server (`npm run server`)
- **Optional LLM integration** - Works with or without OpenAI API key
- **Rich console output** - Animated spinners and memory orchestration visualization
- **Layer observer** - Real-time display of all memory layers
- **Full test suite** - Unit, integration, and E2E tests included

**CLI Commands:**
- `/recall <query>` - Search memories without storing
- `/facts` - List all stored facts
- `/history` - Show conversation history
- `/new` - Start a new conversation
- `/config` - Show current configuration

#### Fixed

**Query Performance** - Resolved "Too many bytes read" error in `agents:computeStats`:

```typescript
// Before: Full table scans hitting 16MB limit
const memories = await ctx.db.query("memories").collect();

// After: Indexed queries with sampling
const SAMPLE_LIMIT = 1000;
const memories = await ctx.db
  .query("memories")
  .withIndex("by_participantId", (q) => q.eq("participantId", args.agentId))
  .take(SAMPLE_LIMIT);
```

- Uses proper indexes for better performance
- Limits results to 1000 per query
- Returns `isApproximate: true` when sampled

**Upgrade:** Run `npx convex deploy` after updating

</details>

---

### CLI v0.28.0 Â· Jan 5, 2026

**Basic Template Tracking & Sessions Support**

ğŸ“ Basic template projects now tracked in CLI config  
ğŸ—ƒï¸ Sessions and factHistory tables added to db commands  
ğŸ“Š Database stats now cover all 13 tables

<details>
<summary>Show full details</summary>

#### Added

- **Basic template tracking in CLI config** - Basic template projects are now registered in `cortex.config.json`:
  - `cortex init` automatically registers basic projects in the `apps` section
  - `cortex update --sync-template` now works with basic template projects
  - `cortex config list` shows basic projects alongside quickstart apps

- **Sessions and factHistory table support** - `cortex db clear` and `cortex db stats` now include all Convex tables:
  - `sessions` - Native session management table
  - `factHistory` - Belief revision audit trail table
  - Statistics now include counts for all 13 tables

#### Changed

- Added `"basic"` to `AppType` union type for template app tracking
- `cortex db clear` now clears 13 tables (was 11)

</details>

---

### TypeScript SDK v0.27.2 Â· Jan 1, 2026

**V6 Route Feature Parity Fix**

ğŸ”§ `/api/chat-v6` route now has full feature parity with v5  
ğŸ§ª Comprehensive E2E tests for quickstart  
âœ… Fact extraction and belief revision working in v6

<details>
<summary>Show full details</summary>

#### Fixed

**`/api/chat-v6` route** now has full feature parity with the v5 route using `createCortexMemoryAsync`:

- âœ… Memory recall (pre-call context injection)
- âœ… Memory storage (post-call conversation saving)
- âœ… Fact extraction (`enableFactExtraction`)
- âœ… Belief revision (superseding outdated facts)
- âœ… Embedding generation for semantic search
- âœ… Layer observer for real-time UI updates

#### Added

Comprehensive E2E tests for the quickstart covering:

- Fact storage verification
- Belief revision (updating preferences through conversation)
- Memory recall across conversations
- V5/V6 parity validation
- Conversation lifecycle (create, list, delete)

</details>

---

### TypeScript SDK v0.27.1 Â· Jan 1, 2026

**AI SDK v6 Agent Architecture Support**

ğŸ¤– Full integration with Vercel AI SDK v6's `ToolLoopAgent`  
ğŸ¯ Type-safe `callOptionsSchema` for runtime configuration  
ğŸ”Œ `createMemoryPrepareCall` for automatic memory injection

<details>
<summary>Show full details</summary>

#### New Exports

```typescript
import {
  createCortexCallOptionsSchema,  // Type-safe call options
  CortexCallOptions,
  createMemoryPrepareCall,        // Memory injection via prepareCall
  MemoryInjectionConfig,
  isV6Available,                  // v6 feature detection
  InferAgentUIMessage,            // Type inference for UI messages
} from "@cortexmemory/vercel-ai-provider";
```

#### Usage with ToolLoopAgent

```typescript
import { ToolLoopAgent } from "ai";

const memoryAgent = new ToolLoopAgent({
  model: "openai/gpt-4o-mini",
  instructions: "You are a helpful assistant with long-term memory.",
  callOptionsSchema: createCortexCallOptionsSchema(),
  prepareCall: createMemoryPrepareCall({
    convexUrl: process.env.CONVEX_URL!,
    maxMemories: 20,
  }),
});

await memoryAgent.generate({
  prompt: "Hello!",
  options: { userId: "u1", memorySpaceId: "app1" },
});
```

#### Auto-Detection

The quickstart automatically detects AI SDK version and routes appropriately:
- **AI SDK v6**: Uses `/api/chat-v6` with `ToolLoopAgent`
- **AI SDK v5**: Uses `/api/chat` with `streamText`

</details>

---

### CLI v0.27.3 Â· Jan 1, 2026

**Neo4j Encrypted URI Scheme Support**

ğŸ” Graph database setup now accepts all neo4j-driver URI schemes  
ğŸ”’ Support for TLS with system CA validation (`+s` suffix)  
ğŸ“œ Support for self-signed certificates (`+ssc` suffix)

<details>
<summary>Show full details</summary>

#### Added

- **Neo4j encrypted URI scheme support** - All neo4j-driver URI schemes now accepted:
  - `bolt://`, `bolt+s://`, `bolt+ssc://` (direct connections)
  - `neo4j://`, `neo4j+s://`, `neo4j+ssc://` (routing/cluster connections)
  - `+s` suffix for TLS with system CA validation
  - `+ssc` suffix for TLS with self-signed certificate acceptance

#### Changed

- Updated Docker Compose graph configuration to support optional TLS
- Added SSL policy configuration for Neo4j bolt connector

</details>

---

## December 2025

### Python SDK v0.27.0 Â· Dec 28, 2025

**Multi-Tenancy & Auth Context System**

ğŸ” Complete multi-tenancy with automatic `tenantId` propagation  
ğŸ“± New Sessions API for multi-session management  
ğŸ‘¤ User profile schemas with validation presets

<details>
<summary>Show full details</summary>

#### New Auth Module (`cortex.auth`)

```python
from cortex.auth import create_auth_context
from cortex import AuthContext, AuthMethod

auth = create_auth_context(
    user_id='user-123',
    tenant_id='tenant-acme',
    organization_id='org-engineering',
    session_id='sess-abc',
    auth_provider='auth0',
    auth_method='oauth',
    claims={'roles': ['admin', 'editor']},
)

cortex = Cortex(CortexConfig(
    convex_url=os.getenv("CONVEX_URL"),
    auth=auth,
))

# All operations automatically scoped to tenant
await cortex.memory.remember(...)
await cortex.conversations.create(...)
await cortex.facts.store(...)
```

#### Sessions API

```python
session = await cortex.sessions.create(CreateSessionParams(
    user_id='user-123',
    tenant_id='tenant-456',
    metadata={'device': 'Chrome on macOS'},
))

await cortex.sessions.touch(session.session_id)
active = await cortex.sessions.get_active('user-123')
await cortex.sessions.end(session.session_id)
```

#### User Profile Schemas

| Preset     | Required Fields    | Email Validation | Max Size |
| ---------- | ------------------ | ---------------- | -------- |
| `strict`   | displayName, email | âœ“                | 64KB     |
| `standard` | displayName        | âœ“                | 256KB    |
| `minimal`  | displayName        | âœ—                | None     |
| `none`     | None               | âœ—                | None     |

</details>

---

### TypeScript SDK v0.27.0 Â· Dec 27, 2025

**Multi-Tenancy & Authentication Context**

ğŸ¢ Complete multi-tenancy support for SaaS platforms  
ğŸ” Automatic `tenantId` propagation across all APIs  
ğŸ“± New Sessions API with governance integration

<details>
<summary>Show full details</summary>

#### AuthContext Integration

```typescript
const cortex = new Cortex({
  convexUrl: process.env.CONVEX_URL,
  auth: {
    userId: "user-123",
    tenantId: "tenant-acme",
    sessionId: "sess-abc",
    authMethod: "clerk",
    authenticatedAt: Date.now(),
    claims: { role: "admin" },
  },
});

// All operations automatically scoped to tenant
await cortex.memory.remember({...});
await cortex.conversations.create({...});
await cortex.facts.store({...});
```

#### Sessions API

```typescript
const session = await cortex.sessions.create({
  userId: "user-123",
  metadata: { device: "mobile", ip: "..." },
});

await cortex.sessions.touch(session.sessionId);
const activeSessions = await cortex.sessions.getActive("user-123");
await cortex.sessions.expireIdle({ maxIdleMs: 30 * 60 * 1000 });
```

#### Key Features

- âœ… Automatic TenantId Propagation
- âœ… Sessions API for multi-session management
- âœ… Auth Validators for format validation
- âœ… Framework-Agnostic (Auth0, Clerk, NextAuth, Firebase)
- âœ… Graph Integration with tenant boundaries
- âœ… GDPR Compatible cascade deletion

</details>

---

### CLI v0.27.2 Â· Dec 28, 2025

**Multi-Deployment Update Command**

ğŸ”„ `cortex update` now checks all enabled deployments by default  
ğŸ“Š Color-coded version status table  
ğŸ¯ Sequential updates with summary

<details>
<summary>Show full details</summary>

#### Added

- **Multi-deployment update command** - `cortex update` now checks all enabled deployments:
  - Displays status table with latest SDK/Convex versions and each deployment's current versions
  - Color-coded display (green = up to date, yellow = needs update)
  - Prompts to confirm updating all deployments that need updates
  - Sequential updates with summary at the end
  - `-d, --deployment <name>` flag for single-deployment mode

</details>

---

### CLI v0.27.1 Â· Dec 27, 2025

**App Lifecycle Management**

ğŸ›‘ Stop command detects and stops running template apps  
ğŸ” Port-based process detection fallback  
ğŸ“Š Enhanced status dashboard with app information

<details>
<summary>Show full details</summary>

#### Added

- **App lifecycle management in `cortex stop`**:
  - `-a, --app <name>` option to stop a specific app
  - `--apps-only` flag to stop only apps (skip Convex/graph)
  - Apps tracked via PID files (`.cortex-app-{name}.pid`)

- **Port-based process detection** when PID files don't exist:
  - Detects Convex on port 3210 for local deployments
  - Detects apps by their configured port (default 3000)

- **Enhanced `cortex status` dashboard**:
  - Displays running apps with PID and port information
  - Shows detection method (via PID file or via port)

</details>

---

### CLI v0.27.0 Â· Dec 26, 2025

**Vercel AI Quickstart Integration**

ğŸš€ Optional demo app installation during `cortex init`  
ğŸ“± Template apps management and tracking  
âš¡ Default enabled for init-created resources

<details>
<summary>Show full details</summary>

#### Added

- **Vercel AI Quickstart integration** - Optional demo app installation:
  - Installs as `/quickstart` subfolder
  - Full Next.js app with chat interface and real-time memory visualization
  - Auto-configured with Convex URL and OpenAI API key

- **Template apps management**:
  - New `apps` section in config (`~/.cortexrc`)
  - Apps shown in `cortex config list`
  - `cortex start` automatically starts enabled apps

- **Default enabled** - Deployments and apps from `cortex init` enabled by default

</details>

---

### TypeScript SDK v0.26.1 Â· Dec 26, 2025

**Vercel AI SDK v6.0 Support**

âœ… Extended peer dependencies to accept `ai` v6.x  
ğŸ”§ No breaking changes - fully backward compatible

<details>
<summary>Show full details</summary>

#### Changed

- **Extended peerDependencies** - `@cortexmemory/vercel-ai-provider` now accepts `ai` versions `^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0`
- Users on Vercel AI SDK v6.x will no longer see peer dependency warnings

</details>

---

### Create v0.26.0 Â· Dec 23, 2025

**Cortex CLI Integration**

ğŸ”§ Optional `@cortexmemory/cli` installation during setup  
ğŸ“œ Adds CLI scripts to generated package.json  
âœ¨ Enhanced success messages with CLI commands

<details>
<summary>Show full details</summary>

#### Added

- **Cortex CLI Integration**:
  - New optional step to install `@cortexmemory/cli` during project setup
  - Automatic CLI installation as dev dependency when selected
  - Adds scripts: `npm run cortex`, `cortex:setup`, `cortex:stats`, `cortex:spaces`

- **User Experience**:
  - Updated configuration summary shows CLI installation status
  - Enhanced success message with CLI commands when installed

</details>

---

### TypeScript SDK v0.26.0 Â· Dec 23, 2025

**Enhanced Belief Revision - Subject+FactType Matching**

ğŸ§  New pipeline stage catches conflicts missed by pattern matching  
ğŸ”‹ "Batteries included" mode - works without LLM configuration  
ğŸ”§ Fixed SUPERSEDE and UPDATE actions

<details>
<summary>Show full details</summary>

#### New Pipeline Stage

```
NEW FACT â†’ [Slot Match] â†’ [Semantic Match] â†’ [Subject+Type Match] â†’ [LLM/Heuristic] â†’ Execute
                                                    â”‚
                                            Same subject AND factType?
                                            â†’ Candidate for review
```

#### Key Improvements

- âœ… **Subject+FactType Matching (Stage 2.5)** - Catches conflicts with same subject AND factType
- âœ… **Batteries-Included Mode** - Works WITHOUT LLM using `getDefaultDecision()` heuristics
- âœ… **Fixed SUPERSEDE Action** - Now uses `facts.supersede` mutation properly
- âœ… **Fixed UPDATE Action** - Uses `updateInPlace` to avoid creating unwanted versions

```typescript
// Works WITHOUT LLM configuration
const cortex = new Cortex({ convexUrl: "..." });

await cortex.memory.remember({
  memorySpaceId: "user-space",
  userMessage: "Actually, I prefer purple now",
  agentResponse: "Got it!",
  userId: "user-123",
});
// Old "blue" fact properly SUPERSEDED
```

</details>

---

### Python SDK v0.26.0 Â· Dec 23, 2025

**OrchestrationObserver API**

ğŸ“Š Real-time monitoring of `remember()` and `remember_stream()` pipeline  
ğŸ› Fixed `user_id` propagation in fact extraction  
ğŸ§  Subject+FactType matching for belief revision

<details>
<summary>Show full details</summary>

#### OrchestrationObserver

```python
class MyObserver:
    def on_orchestration_start(self, orchestration_id: str) -> None:
        print(f"Starting: {orchestration_id}")

    def on_layer_update(self, event: LayerEvent) -> None:
        print(f"Layer {event.layer}: {event.status} ({event.latency_ms}ms)")

    def on_orchestration_complete(self, summary: OrchestrationSummary) -> None:
        print(f"Done in {summary.total_latency_ms}ms")

result = await cortex.memory.remember(
    RememberParams(..., observer=MyObserver())
)
```

#### Bug Fixes

- Fixed `user_id`, `participant_id`, and `source_ref` not propagating to facts during belief revision
- Fixed SUPERSEDE action to use dedicated `facts:supersede` mutation
- Fixed UPDATE action to use `facts:updateInPlace`

</details>

---

### CLI v0.26.2 Â· Dec 25, 2025

**Non-Interactive Convex Setup**

ğŸ¤– Init wizard sets up Convex without interactive prompts  
ğŸ”„ Three streamlined setup paths  
ğŸ”‘ Automatic Convex login handling

<details>
<summary>Show full details</summary>

#### Added

- **Non-interactive Convex setup in `cortex init`**:
  - Automatically detects Convex authentication status
  - Retrieves team slug automatically from login status
  - Uses Convex CLI flags for seamless setup

- **Three streamlined setup paths**:
  - **Local development** - Cloud project with local backend (recommended)
  - **Cloud project** - New cloud deployment with full features
  - **Existing project** - Connect to existing Convex deployment

</details>

---

### CLI v0.26.1 Â· Dec 25, 2025

**Environment Variable Fixes**

ğŸ”§ Fixed `cortex dev` overwriting local deployment configs  
ğŸ”‘ Fixed OpenAI API key not saved during init

<details>
<summary>Show full details</summary>

#### Fixed

- **`cortex dev` overwriting `.env.local`** - Inherited `CONVEX_*` variables were polluting child processes
- **OpenAI API key not saved** - Init wizard now correctly saves the configured key

</details>

---

### CLI v0.26.0 Â· Dec 23, 2025

**Secure Password Generation**

ğŸ” Cryptographically secure passwords for Neo4j/Memgraph  
ğŸ”‘ OpenAI API key setup during init

<details>
<summary>Show full details</summary>

#### Added

- **Secure password generation** - `cortex init` generates 20-character passwords for graph databases
- **OpenAI API key setup** - New optional step with `sk-` prefix validation

</details>

---

### TypeScript SDK v0.24.0 Â· Dec 20, 2025

**Belief Revision System**

ğŸ§  Intelligent fact management preventing duplicates  
ğŸ”„ Slot-based, semantic, and LLM-based conflict resolution  
ğŸ“œ Complete audit trail with fact history

<details>
<summary>Show full details</summary>

#### The Problem Solved

Previously, fact storage was append-only:
- Conflicting facts accumulated
- No semantic understanding of when facts should update vs. add
- No history of how knowledge evolved

#### Now with Belief Revision

```typescript
const result = await cortex.facts.revise({
  memorySpaceId: "user-123-space",
  fact: {
    fact: "User prefers purple",
    subject: "user-123",
    predicate: "favorite color",
    object: "purple",
    confidence: 90,
  },
});

console.log(result.action); // "SUPERSEDE"
console.log(result.reason); // "Color preference has changed"
```

#### New API Methods

| Method | Purpose |
|--------|---------|
| `facts.revise()` | Full belief revision pipeline |
| `facts.checkConflicts()` | Preview conflicts without executing |
| `facts.supersede()` | Manually supersede one fact with another |
| `facts.history()` | Get change history for a fact |
| `facts.getSupersessionChain()` | Get lineage of fact versions |
| `facts.getActivitySummary()` | Analytics on fact changes |

</details>

---

### Python SDK v0.24.0 Â· Dec 19, 2025

**Belief Revision System**

ğŸ§  Intelligent fact management with conflict resolution  
ğŸ”„ Pipeline: Slot matching â†’ Semantic â†’ LLM resolution  
ğŸ“œ Fact history and audit trail

<details>
<summary>Show full details</summary>

#### Usage

```python
result = await cortex.facts.revise(ReviseParams(
    memory_space_id="agent-1",
    fact=ConflictCandidate(
        fact="User prefers purple",
        subject="user-123",
        predicate="favorite color",
        object="purple",
        confidence=90,
    ),
))

print(f"Action: {result.action}")  # SUPERSEDE
print(f"Reason: {result.reason}")  # "Color preference has changed"
```

#### Available Actions

| Action | When Used |
|--------|-----------|
| **ADD** | Genuinely new information |
| **UPDATE** | Refines existing fact |
| **SUPERSEDE** | Replaces contradictory fact |
| **NONE** | Already captured |

</details>

---

### TypeScript SDK v0.23.0 Â· Dec 19, 2025

**Unified Context Retrieval with `recall()`**

ğŸ” The retrieval counterpart to `remember()`  
ğŸ¯ Get LLM-ready context from all memory layers  
ğŸ”— Graph expansion for discovering related context

<details>
<summary>Show full details</summary>

#### Usage

```typescript
const result = await cortex.memory.recall({
  memorySpaceId: "user-123-space",
  query: "user preferences",
});

// Inject directly into LLM prompt
const response = await llm.chat({
  messages: [
    { role: "system", content: `Context:\n${result.context}` },
    { role: "user", content: userMessage },
  ],
});
```

#### Features

- âœ… Batteries Included - All sources enabled by default
- âœ… Graph Expansion - Discovers related context via relationships
- âœ… Unified Deduplication - Removes duplicates across sources
- âœ… Multi-Signal Ranking - Semantic similarity, confidence, importance, recency
- âœ… LLM-Ready Formatting - Structured markdown context

</details>

---

### Python SDK v0.23.0 Â· Dec 19, 2025

**recall() Orchestration API**

ğŸ”® Unified context retrieval counterpart to `remember()`  
ğŸ¯ Multi-signal ranking with configurable weights  
ğŸ“Š Source breakdown in results

<details>
<summary>Show full details</summary>

#### Usage

```python
result = await cortex.memory.recall(
    RecallParams(
        memory_space_id="agent-1",
        query="user preferences",
    )
)

# Use directly in LLM prompts
print(result.context)
```

#### Ranking Algorithm

| Signal | Weight | Description |
|--------|--------|-------------|
| Semantic | 35% | Vector similarity score |
| Confidence | 20% | Fact confidence (0-100) |
| Importance | 15% | Memory importance (0-100) |
| Recency | 15% | Time decay (30-day half-life) |
| Graph Connectivity | 15% | Connected entity count |

</details>

---

### TypeScript SDK v0.22.0 Â· Dec 19, 2025

**Cross-Session Fact Deduplication**

ğŸ¯ Facts no longer duplicated across conversations  
ğŸ”„ Three deduplication strategies: semantic, structural, exact  
â¬†ï¸ Confidence-based updates

<details>
<summary>Show full details</summary>

#### The Problem Solved

```
Session 1: "My name is Alice" â†’ Fact created âœ…
Session 2: "I'm Alice" â†’ Duplicate detected, skipped âœ…
Session 3: "Call me Alice" â†’ Duplicate detected, skipped âœ…
Result: 1 fact instead of 3!
```

#### Deduplication Strategies

| Strategy | Speed | Accuracy |
|----------|-------|----------|
| `semantic` | Slower | Highest |
| `structural` | Fast | Medium |
| `exact` | Fastest | Low |

#### Configuration

```typescript
await cortex.memory.remember({
  ...params,
  factDeduplication: "semantic", // Default
});
```

</details>

---

### Python SDK v0.22.0 Â· Dec 19, 2025

**Cross-Session Fact Deduplication**

ğŸ¯ Automatic duplicate fact prevention  
ğŸ”„ Configurable deduplication strategies  
ğŸ“ˆ Confidence-based updates for higher-quality facts

<details>
<summary>Show full details</summary>

#### The Solution

```python
# Deduplication is ON by default
await cortex.memory.remember(
    RememberParams(
        memory_space_id="agent-1",
        conversation_id="conv-123",
        user_message="I'm Alex",
        agent_response="Nice to meet you!",
        user_id="user-123",
        user_name="Alex",
        agent_id="assistant",
        extract_facts=my_fact_extractor,
    )
)
```

#### Strategies

| Strategy | Speed | Accuracy |
|----------|-------|----------|
| `none` | âš¡ Fastest | None |
| `exact` | âš¡ Fast | Low |
| `structural` | âš¡ Fast | Medium |
| `semantic` | ğŸ¢ Slower | High |

</details>

---

## November 2025

### Vercel AI Provider v0.2.0 Â· Nov 24, 2025

**Enhanced Streaming with rememberStream()**

ğŸš€ Direct integration with `rememberStream()` API  
ğŸ“Š Comprehensive streaming metrics  
ğŸ”„ Progressive fact extraction and graph sync

<details>
<summary>Show full details</summary>

#### New Features

- **Progressive Storage** - Store partial responses during streaming
- **Streaming Hooks** - `onChunk`, `onProgress`, `onError`, `onComplete`
- **Comprehensive Metrics** - First chunk latency, throughput, estimated costs
- **Progressive Fact Extraction** - Extract facts incrementally during streaming
- **Progressive Graph Sync** - Sync to graph databases during streaming
- **Error Recovery** - Resume tokens and partial failure strategies

#### Configuration

```typescript
const cortexMemory = createCortexMemory({
  convexUrl: process.env.CONVEX_URL!,
  memorySpaceId: "my-chat",
  userId: "user-123",
  streamingOptions: {
    storePartialResponse: true,
    progressiveFactExtraction: true,
  },
  streamingHooks: {
    onProgress: (event) => console.log(event),
  },
});
```

</details>

---

### Create v0.2.0 Â· Nov 24, 2025

**Smart Version Detection**

ğŸ” Auto-fetches latest SDK version from npm  
ğŸ”„ Dynamic Convex version sync with peer dependencies  
âœ¨ Graceful fallback to safe defaults

<details>
<summary>Show full details</summary>

#### Added

- CLI now automatically fetches latest SDK version from npm registry
- Dynamically detects correct Convex version from SDK's peerDependencies
- Template always uses `"latest"` for SDK

</details>

---

### Vercel AI Provider v0.1.0 Â· Nov 5, 2025

**Initial Release**

ğŸ‰ First release of Cortex Memory Provider for Vercel AI SDK  
ğŸ”Œ Works with OpenAI, Anthropic, Google, Groq  
ğŸŒ Edge runtime compatible

<details>
<summary>Show full details</summary>

#### Core Features

- `createCortexMemory()` - Factory function for memory-augmented models
- Automatic memory search before each LLM call
- Automatic memory storage after each response
- Works with streaming and non-streaming responses

#### Memory Management

- `cortexMemory.search()` - Manual memory search
- `cortexMemory.remember()` - Manual memory storage
- `cortexMemory.getMemories()` - Retrieve all memories
- `cortexMemory.clearMemories()` - Delete memories

</details>

---

### Create v0.1.0 Â· Nov 2, 2025

**Initial Release**

ğŸ‰ Interactive CLI wizard for Cortex project setup  
ğŸ³ Docker integration for Neo4j/Memgraph  
ğŸ“¦ Complete project scaffolding

<details>
<summary>Show full details</summary>

#### Features

- `npm create cortex-memories` - Zero-config project creation
- Three Convex setup modes (local/new cloud/existing)
- Optional graph database integration (Neo4j/Memgraph)
- Docker detection with platform-specific instructions
- Automatic dependency installation
- Backend function deployment

</details>

---

### CLI v0.1.0 Â· Nov 29, 2025

**Initial Release**

ğŸ‰ First release of @cortexmemory/cli  
ğŸ“‹ Complete command suite for memory management  
ğŸ”§ Multi-deployment support

<details>
<summary>Show full details</summary>

#### Core Commands

- **Memory Operations** - `memory list`, `search`, `delete`, `export`, `stats`
- **User Management** - `users list`, `get`, `delete`, `export`, GDPR cascade deletion
- **Memory Spaces** - `spaces list`, `create`, `delete`, `archive`, participants management
- **Facts Operations** - `facts list`, `search`, `get`, `delete`, `export`
- **Conversations** - `conversations list`, `get`, `delete`, `export`
- **Convex Management** - `convex status`, `deploy`, `dev`, `logs`, `dashboard`
- **Database Operations** - `db stats`, `clear`, `backup`, `restore`, `export`

#### Features

- Configuration management with multiple deployment support
- Table, JSON, and CSV output formats
- Interactive confirmations for dangerous operations
- Dry-run mode for previewing changes

</details>

---

</TabItem>

<TabItem value="ts-sdk" label="TypeScript SDK">

## January 2026

### v0.28.0 Â· Jan 5, 2026 - Basic Template & Query Fixes

ğŸ¯ New headless template with dual CLI/server modes  
âš¡ Fixed "too many bytes" error in stats queries  
ğŸ§ª Complete test suite with E2E coverage

### v0.27.2 Â· Jan 1, 2026 - V6 Route Feature Parity

ğŸ”§ `/api/chat-v6` route now has full feature parity with v5

### v0.27.1 Â· Jan 1, 2026 - AI SDK v6 Agent Support

ğŸ¤– Full integration with `ToolLoopAgent`  
ğŸ¯ Type-safe `callOptionsSchema`  
ğŸ”Œ `createMemoryPrepareCall` for memory injection

---

## December 2025

### v0.27.0 Â· Dec 27 - Multi-Tenancy & Auth Context

ğŸ¢ Complete multi-tenancy for SaaS platforms  
ğŸ” Automatic `tenantId` propagation  
ğŸ“± New Sessions API

### v0.26.1 Â· Dec 26 - Vercel AI SDK v6.0 Support

âœ… Extended peer dependencies to accept `ai` v6.x

### v0.26.0 Â· Dec 23 - Enhanced Belief Revision

ğŸ§  Subject+FactType matching (Stage 2.5)  
ğŸ”‹ "Batteries included" mode  
ğŸ”§ Fixed SUPERSEDE and UPDATE actions

### v0.24.0 Â· Dec 20 - Belief Revision System

ğŸ§  Intelligent fact management  
ğŸ“œ Complete audit trail

### v0.23.0 Â· Dec 19 - `recall()` API

ğŸ” Unified context retrieval  
ğŸ¯ LLM-ready context generation

### v0.22.0 Â· Dec 19 - Cross-Session Fact Deduplication

ğŸ¯ Automatic duplicate prevention

</TabItem>

<TabItem value="py-sdk" label="Python SDK">

## December 2025

### v0.27.0 Â· Dec 28 - Multi-Tenancy & Auth Context

ğŸ” Complete multi-tenancy with `tenantId` propagation  
ğŸ“± New Sessions API  
ğŸ‘¤ User profile schemas with validation

### v0.26.0 Â· Dec 23 - OrchestrationObserver API

ğŸ“Š Real-time pipeline monitoring  
ğŸ› Fixed `user_id` propagation  
ğŸ§  Subject+FactType matching

### v0.24.0 Â· Dec 19 - Belief Revision System

ğŸ§  Intelligent fact management  
ğŸ”„ Pipeline: Slot â†’ Semantic â†’ LLM  
ğŸ“œ Fact history and audit trail

### v0.23.0 Â· Dec 19 - `recall()` API

ğŸ”® Unified context retrieval  
ğŸ¯ Multi-signal ranking

### v0.22.0 Â· Dec 19 - Cross-Session Fact Deduplication

ğŸ¯ Automatic duplicate prevention  
ğŸ”„ Configurable strategies

</TabItem>

<TabItem value="cli" label="CLI">

## January 2026

### v0.28.1 Â· Jan 6 - Shell Tab Completion

âŒ¨ï¸ Auto-installs for zsh, bash, fish  
âœ¨ Dynamic completion for deployments

### v0.28.0 Â· Jan 5 - Basic Template Tracking

ğŸ“ Basic projects tracked in config  
ğŸ—ƒï¸ Sessions and factHistory support

### v0.27.3 Â· Jan 1 - Neo4j Encrypted URIs

ğŸ” All neo4j-driver URI schemes supported

---

## December 2025

### v0.27.2 Â· Dec 28 - Multi-Deployment Updates

ğŸ”„ `cortex update` checks all deployments  
ğŸ“Š Color-coded version status

### v0.27.1 Â· Dec 27 - App Lifecycle Management

ğŸ›‘ Stop running template apps  
ğŸ” Port-based process detection

### v0.27.0 Â· Dec 26 - Quickstart Integration

ğŸš€ Optional demo app installation  
ğŸ“± Template apps management

### v0.26.2 Â· Dec 25 - Non-Interactive Convex Setup

ğŸ¤– Streamlined setup paths

### v0.26.1 Â· Dec 25 - Environment Fixes

ğŸ”§ Fixed `.env.local` overwrites

### v0.26.0 Â· Dec 23 - Secure Passwords

ğŸ” Cryptographically secure passwords

---

## November 2025

### v0.1.0 Â· Nov 29 - Initial Release

ğŸ‰ Complete CLI for Cortex memory management

</TabItem>

<TabItem value="vercel" label="Vercel AI">

## November 2025

### v0.2.0 Â· Nov 24 - Enhanced Streaming

ğŸš€ Direct `rememberStream()` integration  
ğŸ“Š Streaming metrics  
ğŸ”„ Progressive fact extraction

### v0.1.0 Â· Nov 5 - Initial Release

ğŸ‰ Cortex Memory Provider for Vercel AI SDK  
ğŸ”Œ Works with OpenAI, Anthropic, Google, Groq

</TabItem>

<TabItem value="create" label="Create">

## December 2025

### v0.26.0 Â· Dec 23 - CLI Integration

ğŸ”§ Optional `@cortexmemory/cli` installation

---

## November 2025

### v0.2.0 Â· Nov 24 - Smart Version Detection

ğŸ” Auto-fetches latest SDK version  
ğŸ”„ Dynamic Convex version sync

### v0.1.0 Â· Nov 2 - Initial Release

ğŸ‰ Interactive CLI wizard for project setup

</TabItem>
</Tabs>

---

## Versioning Policy

Cortex packages follow semantic versioning:

- **Major (X.0.0)**: Breaking API changes
- **Minor (0.X.0)**: New features, backwards compatible
- **Patch (0.0.X)**: Bug fixes, backwards compatible

## Deprecation Policy

- Features are marked deprecated for at least one minor version before removal
- Deprecated features include migration guides
- Breaking changes are documented with upgrade paths

---

## Roadmap

### Planned for v1.0.0

- Complete API stabilization
- Integration examples for all major frameworks
- Real-time graph sync worker
- MCP Server implementation
- Cloud Mode with Graph-Premium
