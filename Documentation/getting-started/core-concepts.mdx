---
id: core-concepts
title: Core Concepts
sidebar_position: 4
description: Understand memory spaces, layers, and the Cortex architecture
---

import { Callout, FeatureGrid, FeatureCard, Steps, Step, QuickNav, QuickNavItem, ComparisonTable, Terminal, CodeBlock, Accordion, AccordionItem, Diagram } from '@site/src/components';
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Core Concepts

Understanding these core concepts will help you make the most of Cortex. This guide covers the fundamental building blocks of the system.

<Callout type="info" title="Feature Availability">
  Cortex offers two deployment modes (Direct and Cloud). This guide covers all core concepts regardless of mode. As we develop the platform, certain advanced features may be available only in cloud mode. We'll clearly mark these distinctions as they're finalized.
</Callout>

## Key Concepts at a Glance

<FeatureGrid columns={2}>
  <FeatureCard
    icon="ğŸ“¦"
    title="Memory Spaces"
    description="Isolated storage boundaries for users, teams, or projects"
    href="/core-features/memory-spaces"
  />
  <FeatureCard
    icon="ğŸ"
    title="Hive Mode"
    description="Multiple tools share one memory space for seamless collaboration"
    href="/core-features/hive-mode"
  />
  <FeatureCard
    icon="â™¾ï¸"
    title="Infinite Context"
    description="Never run out of context with retrieval-based memory"
    href="/architecture/infinite-context"
  />
  <FeatureCard
    icon="ğŸ”—"
    title="Context Chains"
    description="Hierarchical context for multi-agent systems"
    href="/core-features/context-chains"
  />
  <FeatureCard
    icon="ğŸ”"
    title="Semantic Search"
    description="AI-powered memory retrieval by meaning, not just keywords"
    href="/core-features/semantic-search"
  />
  <FeatureCard
    icon="ğŸ“Š"
    title="Analytics"
    description="Track memory usage, access patterns, and performance"
    href="/core-features/access-analytics"
  />
</FeatureGrid>

---

## Memory Spaces

### What is a Memory Space?

A **memory space** is the fundamental isolation boundary in Cortex. Think of it as a private namespace where memories, facts, and conversations are stored.

<Callout type="tip" title="Think of Memory Spaces Like...">
  A memory space is like a personal hard drive or team workspace. Everything inside is isolated from other spaces, but authorized participants can read and write freely within the space.
</Callout>

<Callout type="note" title="Previous Terminology">
  We used to call these "agents" - but that was confusing because multiple agents (or tools) can share one memory space!
</Callout>

<CodeBlock filename="types.ts" language="typescript">
{`interface MemorySpace {
  id: string; // e.g., "user-123-personal" or "team-engineering"
  name?: string; // Human-readable name
  type: "personal" | "team" | "project"; // Organization type
  participants: string[]; // Who operates in this space (Hive Mode)
  createdAt: Date;
}`}
</CodeBlock>

### Key Concept: Memory Space = Isolation Boundary

<Callout type="warning" title="Key Distinction">
  `memorySpaceId` is the isolation boundary, NOT `agentId`. Multiple agents can share a memory space (Hive Mode) or have separate spaces (Collaboration Mode).
</Callout>

<CodeBlock filename="example.ts" language="typescript">
{`// Every memory operation requires a memorySpaceId
await cortex.memory.remember({
  memorySpaceId: "user-123-personal", // â† Isolation boundary
  participantId: "cursor", // â† Who is storing this (optional)
  conversationId: "conv-123",
  userMessage: "I prefer TypeScript",
  agentResponse: "Noted!",
  userId: "user-123",
  userName: "User",
});`}
</CodeBlock>

### What's Isolated vs Shared

<Tabs>
  <TabItem value="isolated" label="Isolated Per Space">
    **Stored within each memory space:**

    - âœ… Layer 1a: Conversations (raw message history)
    - âœ… Layer 2: Vector memories (embeddings + search)
    - âœ… Layer 3: Facts (LLM-extracted knowledge)
    - âœ… Layer 4: Convenience API results
  </TabItem>
  <TabItem value="shared" label="Shared Across All">
    **Shared across ALL memory spaces:**

    - âœ… Layer 1b: Immutable Store (policies, KB, org docs)
    - âœ… Layer 1c: Mutable Store (config, inventory, counters)
    - âœ… User profiles
    - âœ… Agent/Participant registry
  </TabItem>
</Tabs>

### Why Memory Spaces?

<ComparisonTable 
  headers={["Aspect", "Before (Agent-Centric)", "After (Memory-Space-Centric)"]}
  items={[
    { feature: "Architecture", values: ["Each agent had separate memories", "Tools share a memory space"] },
    { feature: "Example", values: ["Cursor stores 'User prefers TypeScript'", "Cursor stores in user-123-personal"] },
    { feature: "Problem/Solution", values: ["Claude can't see it (different agent)", "Claude reads from user-123-personal"] },
    { feature: "Result", values: ["User repeats preferences to every tool âŒ", "Memory follows user across tools âœ…"] },
  ]}
/>

### Creating Memory Spaces

<Tabs>
  <TabItem value="implicit" label="Implicit (Recommended)">
    <CodeBlock filename="implicit-creation.ts" language="typescript">
{`// Just use memorySpaceId - space created automatically
await cortex.memory.remember({
  memorySpaceId: "user-123-personal", // Created on first use
  conversationId: "conv-123",
  userMessage: "Hello",
  agentResponse: "Hi!",
  userId: "user-123",
  userName: "Alice",
});`}
    </CodeBlock>
  </TabItem>
  <TabItem value="explicit" label="Explicit (For Analytics)">
    <CodeBlock filename="explicit-registration.ts" language="typescript">
{`// Register space for rich metadata and analytics
await cortex.memorySpaces.register({
  id: "user-123-personal",
  name: "Alice's Personal Space",
  type: "personal",
  participants: ["cursor", "claude", "custom-bot"],
  metadata: {
    owner: "user-123",
    created: new Date(),
  },
});

// Now you get enhanced analytics
const stats = await cortex.analytics.getMemorySpaceStats("user-123-personal");
// { memoriesStored: 543, participants: 3, avgAccessTime: '12ms', ... }`}
    </CodeBlock>
  </TabItem>
  <TabItem value="cli" label="CLI">
    <Terminal title="List all memory spaces">cortex spaces list</Terminal>
    <Terminal title="Create a memory space">cortex spaces create user-123-personal --type personal --name "Alice's Personal Space"</Terminal>
    <Terminal title="View space statistics">cortex spaces stats user-123-personal</Terminal>
    <Terminal title="List participants (Hive Mode)">cortex spaces participants user-123-personal</Terminal>
  </TabItem>
</Tabs>

**Learn more:**
- [Memory Spaces Guide](/core-features/memory-spaces)
- [CLI: spaces commands](/tools/cli-reference#cortex-spaces)

---

## Hive Mode vs Collaboration Mode

Cortex supports two architectural patterns for multi-agent/multi-tool systems:

<Diagram title="Operating Modes" caption="Choose the mode that fits your architecture">
{`flowchart TD
    subgraph Hive["Hive Mode"]
        U1[User] --> MS1[Shared Memory Space]
        MS1 --> C[Cursor]
        MS1 --> CL[Claude]
        MS1 --> CB[Custom Bot]
    end
    
    subgraph Collab["Collaboration Mode"]
        U2[User] --> FA[Finance Agent]
        U2 --> HA[HR Agent]
        FA --> MS2[Finance Space]
        HA --> MS3[HR Space]
        MS2 <-.->|A2A| MS3
    end`}
</Diagram>

### Hive Mode: Shared Memory Space

**Multiple participants share ONE memory space.**

<CodeBlock filename="hive-mode.ts" language="typescript">
{`// Cursor stores memory
await cortex.memory.remember({
  memorySpaceId: "user-123-personal", // Shared space
  participantId: "cursor", // Who stored it
  userMessage: "I prefer dark mode",
  agentResponse: "Noted!",
  userId: "user-123",
  userName: "Alice",
});

// Claude reads from SAME space
const memories = await cortex.memory.search("user-123-personal", "preferences");
// Returns: [{ content: "User prefers dark mode", participantId: "cursor", ... }]`}
</CodeBlock>

<FeatureGrid columns={2}>
  <FeatureCard icon="ğŸ“" title="Single Write" description="One tool stores, all tools benefit" />
  <FeatureCard icon="ğŸš«" title="Zero Duplication" description="One copy of each memory" />
  <FeatureCard icon="ğŸ”„" title="Consistent State" description="Everyone sees the same data" />
  <FeatureCard icon="ğŸ‘¥" title="Participant Tracking" description="participantId shows who stored what" />
</FeatureGrid>

<Callout type="tip" title="Perfect For">
  MCP integrations, personal AI assistants, tool ecosystems, cross-application memory
</Callout>

### Collaboration Mode: Separate Memory Spaces

**Each participant has SEPARATE memory space, communicates via A2A.**

<CodeBlock filename="collaboration-mode.ts" language="typescript">
{`// Finance agent stores in its own space
await cortex.memory.remember({
  memorySpaceId: "finance-agent-space", // Finance's space
  conversationId: "conv-123",
  userMessage: "Approve $50k budget",
  agentResponse: "Approved",
  userId: "user-123",
  userName: "CFO",
});

// Send message to HR agent (dual-write to BOTH spaces)
await cortex.a2a.send({
  from: "finance-agent",
  to: "hr-agent",
  message: "Budget approved for hiring",
  importance: 85,
  metadata: { tags: ["approval", "hiring"] },
});
// Automatically stored in BOTH finance-agent-space AND hr-agent-space`}
</CodeBlock>

<FeatureGrid columns={2}>
  <FeatureCard icon="âœï¸" title="Dual-Write" description="A2A messages stored in both spaces" />
  <FeatureCard icon="ğŸ”’" title="Complete Isolation" description="Each space is independent" />
  <FeatureCard icon="âš–ï¸" title="No Conflicts" description="Separate memories can't conflict" />
  <FeatureCard icon="ğŸ›¡ï¸" title="GDPR Compliant" description="Delete one space without affecting others" />
</FeatureGrid>

<Callout type="tip" title="Perfect For">
  Autonomous agent swarms, enterprise workflows, multi-tenant systems, regulated industries
</Callout>

### Comparison Table

<ComparisonTable 
  headers={["Hive Mode", "Collaboration Mode"]}
  highlightColumn={0}
  items={[
    { feature: "Memory Spaces", values: ["1 shared space", "N separate spaces"] },
    { feature: "Storage", values: ["Single write", "Dual-write (A2A)"] },
    { feature: "Consistency", values: ["Always consistent", "Eventually consistent"] },
    { feature: "Isolation", values: ["None (by design)", "Complete"] },
    { feature: "Use Case", values: ["Personal AI tools", "Autonomous agents"] },
    { feature: "Participant Tracking", values: ["Via participantId", "Via fromAgent/toAgent"] },
    { feature: "Example", values: ["Cursor + Claude", "Finance agent + HR agent"] },
  ]}
/>

### Cross-MemorySpace Access (Context Chains)

Even in Collaboration Mode, spaces can grant **limited** access via context chains:

<CodeBlock filename="cross-space-access.ts" language="typescript">
{`// Supervisor creates context and delegates
const context = await cortex.contexts.create({
  purpose: "Process refund request",
  memorySpaceId: "supervisor-space",
  userId: "user-123",
});

// Specialist can access supervisor's context (read-only)
const fullContext = await cortex.contexts.get(context.id, {
  includeChain: true,
  requestingSpace: "specialist-space", // Cross-space access
});

// specialist-space can read:
// âœ… The context chain (hierarchy)
// âœ… Referenced conversations (only those in context)
// âŒ Supervisor's other memories (isolated)`}
</CodeBlock>

<Callout type="warning" title="Security Model">
  Context chains grant **limited** read access. Only context-referenced data is accessible. All cross-space reads are logged for audit trails, preventing memory poisoning.
</Callout>

---

## Infinite Context

**The Breakthrough:** Never run out of context again.

### The Problem

<Callout type="danger" title="Traditional Approach Limitation">
  Traditional AI chatbots accumulate conversation history until they hit token limits, causing earlier context to be truncated and forgotten.
</Callout>

<CodeBlock filename="traditional-problem.ts" language="typescript">
{`// Traditional approach (accumulation)
const conversation = {
  messages: [
    { role: "user", content: "Hi, I prefer TypeScript" },
    { role: "assistant", content: "Noted!" },
    // ... 500 more exchanges ...
    { role: "user", content: "What languages do I prefer?" },
    { role: "assistant", content: "???" }, // Message #1 was truncated!
  ],
};

// Token cost: 500 messages Ã— 50 tokens = 25,000 tokens per request
// Eventually: Exceeds model's context window (128K, 200K, etc.)`}
</CodeBlock>

### The Solution: Retrieval-Based Context

Instead of sending all history, **retrieve only relevant memories**:

<CodeBlock filename="infinite-context.ts" language="typescript" showLineNumbers={true} highlightLines={[3, 4, 5, 6, 7, 8, 9, 10, 11]}>
{`async function respondToUser(userMessage: string, memorySpaceId: string) {
  // 1. Retrieve relevant context from ALL past conversations
  const relevantContext = await cortex.memory.search(
    memorySpaceId,
    userMessage,
    {
      embedding: await embed(userMessage),
      limit: 10, // Top 10 most relevant facts/memories
    },
  );

  // 2. LLM call with ONLY relevant context
  const response = await llm.complete({
    messages: [
      {
        role: "system",
        content: \`Relevant Context:\\n\${relevantContext.map((m) => m.content).join("\\n")}\`,
      },
      { role: "user", content: userMessage }, // Current message only
    ],
  });

  // 3. Store exchange (adds to knowledge pool)
  await cortex.memory.remember({
    memorySpaceId,
    conversationId: \`ephemeral-\${Date.now()}\`,
    userMessage,
    agentResponse: response,
    userId: "user-123",
    userName: "User",
    extractFacts: true, // Auto-extract for future retrieval
  });

  return response;
}`}
</CodeBlock>

### Key Benefits

<FeatureGrid columns={2}>
  <FeatureCard
    icon="â™¾ï¸"
    title="Unlimited History"
    description="Recall from 1,000,000+ past messages. Token cost stays constant."
  />
  <FeatureCard
    icon="ğŸ’°"
    title="99% Token Reduction"
    description="From 50,000 tokens to 400 tokens. $1.50 â†’ $0.012 per request."
  />
  <FeatureCard
    icon="ğŸ¤–"
    title="Works with Any Model"
    description="Smaller, cheaper models can have 'infinite' memory."
  />
  <FeatureCard
    icon="ğŸ¯"
    title="Perfect Recall"
    description="Semantic search finds relevant info from years ago."
  />
</FeatureGrid>

### 3-Tier Retrieval Strategy

<Tabs>
  <TabItem value="tier1" label="Tier 1: Facts">
    **Most efficient** - Compressed knowledge

    ```typescript
    const facts = await cortex.memory.search(memorySpaceId, query, {
      contentType: "fact",
      limit: 10,
    });
    // 10 facts Ã— 8 tokens = 80 tokens
    ```
  </TabItem>
  <TabItem value="tier2" label="Tier 2: Summaries">
    **More detail** - Condensed conversations

    ```typescript
    const summaries = await cortex.memory.search(memorySpaceId, query, {
      contentType: "summarized",
      limit: 3,
    });
    // 3 summaries Ã— 75 tokens = 225 tokens
    ```
  </TabItem>
  <TabItem value="tier3" label="Tier 3: Raw">
    **Full detail** - Original content (selective)

    ```typescript
    const critical = facts.filter((f) => f.metadata.importance >= 90);
    const raw = await fetchRawForFacts(critical.slice(0, 2));
    // 2 conversations Ã— 50 tokens = 100 tokens
    ```
  </TabItem>
</Tabs>

<Callout type="tip" title="Total Token Usage">
  Combined: 405 tokens vs 20,000+ tokens accumulated!
</Callout>

**Learn more:** [Infinite Context Architecture](/architecture/infinite-context)

---

## Memory

### What is Memory?

In Cortex, a **memory** is a piece of information stored in a memory space for later retrieval.

<CodeBlock filename="memory-types.ts" language="typescript">
{`interface MemoryEntry {
  id: string; // Unique identifier
  memorySpaceId: string; // Which space owns this
  participantId?: string; // Who stored it (Hive Mode)
  content: string; // The actual information
  embedding?: number[]; // Vector for semantic search
  metadata: {
    importance: number; // 0-100 scale
    tags: string[]; // Categorization
    [key: string]: any; // Custom metadata
  };
  createdAt: Date; // When stored
  lastAccessed?: Date; // Last retrieval
  accessCount: number; // Usage tracking
}`}
</CodeBlock>

### Types of Memories

<Accordion>
  <AccordionItem title="Conversation Memories" defaultOpen={true}>
    Information from user interactions:

    ```typescript
    await cortex.memory.remember({
      memorySpaceId: "user-123-personal",
      conversationId: "conv-123",
      userMessage: "I work in San Francisco",
      agentResponse: "That's great to know!",
      userId: "user-123",
      userName: "Alice",
      importance: 60,
      tags: ["location", "personal", "user-info"],
    });
    ```
  </AccordionItem>
  <AccordionItem title="Knowledge Memories">
    Facts and system-generated information:

    ```typescript
    await cortex.vector.store("user-123-personal", {
      content: "Product X costs $49.99 with a 20% discount for annual billing",
      contentType: "raw",
      embedding: await embed("Product X pricing"),
      source: { type: "system", timestamp: new Date() },
      metadata: {
        importance: 85,
        tags: ["pricing", "product-x", "business"],
      },
    });
    ```
  </AccordionItem>
  <AccordionItem title="Task Memories">
    What was done (tool results, actions):

    ```typescript
    await cortex.vector.store("support-bot-space", {
      content: "Sent password reset email to user@example.com at 2025-10-28 10:30",
      contentType: "raw",
      embedding: await embed("password reset action"),
      source: { type: "tool", timestamp: new Date() },
      metadata: {
        importance: 90,
        tags: ["action", "security", "completed"],
      },
    });
    ```
  </AccordionItem>
  <AccordionItem title="Participant-to-Participant (Hive Mode)">
    Communications within a shared space:

    ```typescript
    await cortex.memory.remember({
      memorySpaceId: "team-workspace",
      participantId: "finance-bot",
      conversationId: "internal-comm",
      userMessage: "[From hr-bot] New hire approved",
      agentResponse: "Budget allocated for salary",
      userId: "system",
      userName: "System",
      importance: 85,
      tags: ["internal", "coordination"],
    });
    ```
  </AccordionItem>
  <AccordionItem title="Agent-to-Agent (Collaboration Mode)">
    Communications between separate spaces:

    ```typescript
    await cortex.a2a.send({
      from: "finance-agent",
      to: "ceo-agent",
      message: "Received approval for $50k budget increase",
      importance: 85,
      metadata: { tags: ["approval", "budget"] },
    });
    // Stores in BOTH finance-agent-space AND ceo-agent-space
    ```
  </AccordionItem>
</Accordion>

### Memory Versioning (Automatic)

<Callout type="info" title="Revolutionary Feature">
  When you update a memory, the old version is **automatically preserved**. No data loss, temporal conflict resolution, and complete audit trails - all automatic!
</Callout>

<CodeBlock filename="versioning.ts" language="typescript">
{`// Store password (Layer 4 for conversation)
const result = await cortex.memory.remember({
  memorySpaceId: "user-123-personal",
  conversationId: "conv-456",
  userMessage: "The password is Blue",
  agentResponse: "I've saved that password",
  userId: "user-123",
  userName: "Alice",
  importance: 100, // Critical
});
const memoryId = result.memories[0].id;

// Password changes (Layer 4 update - creates version 2)
await cortex.memory.update("user-123-personal", memoryId, {
  content: "The password is Red",
});

// Both versions are preserved!
const memory = await cortex.memory.get("user-123-personal", memoryId);
console.log(memory.content); // "The password is Red" (current)
console.log(memory.version); // 2

console.log(memory.previousVersions[0]);
// { version: 1, content: "The password is Blue", timestamp: ... }`}
</CodeBlock>

### Memory Importance Scale

Cortex uses a granular 0-100 importance scale for precise prioritization:

<ComparisonTable 
  headers={["Range", "Level", "Examples"]}
  items={[
    { feature: "90-100", values: ["Critical", "Passwords (100), Hard deadlines (95), Security alerts (95)"] },
    { feature: "70-89", values: ["High", "User requirements (80), Important decisions (85), Key preferences (75)"] },
    { feature: "40-69", values: ["Medium", "General preferences (60), Conversation context (50), Background info (45)"] },
    { feature: "10-39", values: ["Low", "Casual observations (30), Minor details (20), Exploratory conversation (25)"] },
    { feature: "0-9", values: ["Trivial", "Debug information (5), Temporary data (0)"] },
  ]}
/>

---

## Embeddings

### What are Embeddings?

**Embeddings** are numerical vectors that represent the semantic meaning of text. They enable semantic search - finding related content by meaning, not just keywords.

```
"The cat sat on the mat"
â†“
[0.234, -0.891, 0.445, ..., 0.123]  // 768, 1536, or 3072 dimensions
```

### Embedding-Agnostic Design

<Callout type="info" title="Bring Your Own Embeddings">
  The Cortex SDK does not generate embeddings - you bring your own provider, or use Cortex Cloud for automatic generation.
</Callout>

<Tabs>
  <TabItem value="direct" label="Direct Mode (SDK)">
    <CodeBlock filename="direct-mode.ts" language="typescript">
{`// Choose your provider
const embedding = await yourEmbeddingProvider.embed(text);

// Cortex SDK stores and searches
await cortex.vector.store(memorySpaceId, {
  content: text,
  contentType: "raw",
  embedding: embedding, // Your vectors
  source: { type: "system", timestamp: new Date() },
  metadata: { importance: 50 },
});`}
    </CodeBlock>
  </TabItem>
  <TabItem value="cloud" label="Cloud Mode (Managed)">
    <CodeBlock filename="cloud-mode.ts" language="typescript">
{`// Cortex Cloud generates embeddings automatically
await cortex.memory.remember({
  memorySpaceId,
  conversationId,
  userMessage,
  agentResponse,
  userId,
  userName,
  autoEmbed: true, // â† Cloud Mode generates embeddings for you
  // No embedding provider needed!
});`}
    </CodeBlock>
  </TabItem>
</Tabs>

### Popular Embedding Providers

<Tabs>
  <TabItem value="openai" label="OpenAI">
    ```typescript
    import OpenAI from "openai";
    const openai = new OpenAI();

    const result = await openai.embeddings.create({
      model: "text-embedding-3-large", // 3072 dimensions
      input: text,
    });

    const embedding = result.data[0].embedding;
    ```
  </TabItem>
  <TabItem value="cohere" label="Cohere">
    ```typescript
    import { CohereClient } from "cohere-ai";
    const cohere = new CohereClient();

    const result = await cohere.embed({
      texts: [text],
      model: "embed-english-v3.0", // 1024 dimensions
      inputType: "search_document",
    });

    const embedding = result.embeddings[0];
    ```
  </TabItem>
  <TabItem value="local" label="Local (Transformers.js)">
    ```typescript
    import { pipeline } from "@xenova/transformers";

    const extractor = await pipeline(
      "feature-extraction",
      "Xenova/all-MiniLM-L6-v2",
    ); // 384 dimensions

    const output = await extractor(text, {
      pooling: "mean",
      normalize: true,
    });

    const embedding = Array.from(output.data);
    ```
  </TabItem>
</Tabs>

### Dimension Tradeoffs

<ComparisonTable 
  headers={["Dimensions", "Speed", "Accuracy", "Cost", "Use Case"]}
  items={[
    { feature: "384-768", values: ["Fast", "Good", "Low", "High-volume, real-time"] },
    { feature: "1536", values: ["Medium", "Better", "Medium", "General purpose"] },
    { feature: "3072", values: ["Slower", "Best", "High", "When accuracy is critical"] },
  ]}
/>

<Callout type="tip" title="Recommendation">
  Default to 3072 dimensions (OpenAI text-embedding-3-large) for best accuracy. Scale down if you need faster search.
</Callout>

---

## Search Strategies

Cortex uses **multi-strategy search** for robust memory retrieval.

<Diagram title="Search Flow" caption="How Cortex finds the right memories">
{`flowchart TD
    Q[User Query] --> S1{Semantic Search}
    S1 -->|Results Found| R1[Return Results]
    S1 -->|No Results| S2{Keyword Search}
    S2 -->|Results Found| R2[Return Results]
    S2 -->|No Results| S3[Return Recent Memories]
    S3 --> R3[Always Returns Something]`}
</Diagram>

<Tabs>
  <TabItem value="semantic" label="Strategy 1: Semantic (Vector)">
    Primary method - finds similar meanings:

    ```typescript
    const memories = await cortex.memory.search(
      "user-123-personal",
      "what is the user's favorite color?",
      {
        embedding: await embed("what is the user's favorite color?"),
        limit: 10,
      },
    );
    ```

    This finds: "User loves blue" even though query says "favorite" and "color" separately.
  </TabItem>
  <TabItem value="keyword" label="Strategy 2: Keyword">
    Fallback when vector search finds nothing:

    ```typescript
    // Extracts keywords: ['user', 'favorite', 'color']
    // Searches for any memory containing these words
    ```

    Useful for exact term matching, names/IDs, and technical terms.
  </TabItem>
  <TabItem value="recent" label="Strategy 3: Recent">
    Final fallback - returns recent memories:

    ```typescript
    // When all else fails, return the 20 most recent memories
    // User might find what they need through recency
    ```
  </TabItem>
</Tabs>

### Custom Search Options

<CodeBlock filename="search-options.ts" language="typescript">
{`await cortex.memory.search("user-123-personal", query, {
  embedding: await embed(query),
  limit: 20, // Max results
  minScore: 0.7, // Similarity threshold
  tags: ["preferences"], // Filter by tags
  minImportance: 50, // Minimum importance (0-100 scale)
  createdAfter: new Date("2025-01-01"),
  createdBefore: new Date("2025-01-31"),
  participantId: "cursor", // Only from cursor (Hive Mode)
});`}
</CodeBlock>

**Learn more:**
- [Semantic Search Guide](/core-features/semantic-search)
- [CLI: memory commands](/tools/cli-reference#cortex-memory)

---

## User Profiles

**User profiles** store information about users across all memory spaces and conversations.

<CodeBlock filename="user-profile.ts" language="typescript">
{`interface UserProfile {
  id: string; // Unique user ID
  displayName: string; // How to address them
  email?: string; // Contact info
  preferences: {
    theme?: "light" | "dark";
    language?: string;
    timezone?: string;
    [key: string]: any; // Custom preferences
  };
  metadata: {
    tier?: "free" | "pro" | "enterprise";
    signupDate?: Date;
    lastSeen?: Date;
    [key: string]: any; // Custom metadata
  };
}`}
</CodeBlock>

<Tabs>
  <TabItem value="create" label="Create/Update">
    ```typescript
    await cortex.users.update("user-123", {
      displayName: "Alice Johnson",
      email: "alice@example.com",
      preferences: {
        theme: "dark",
        language: "en",
        timezone: "America/Los_Angeles",
      },
      metadata: {
        tier: "pro",
        signupDate: new Date(),
        company: "Acme Corp",
      },
    });
    ```
  </TabItem>
  <TabItem value="retrieve" label="Retrieve">
    ```typescript
    const user = await cortex.users.get("user-123");

    // Use in agent interactions
    const greeting = `Hello ${user.displayName}! I see you prefer ${user.preferences.theme} mode.`;
    ```
  </TabItem>
  <TabItem value="cli" label="CLI">
    <Terminal title="List all users">cortex users list</Terminal>
    <Terminal title="Get user details">cortex users get user-123</Terminal>
    <Terminal title="Export user data (GDPR)">cortex users export user-123 --output user-data.json</Terminal>
    <Terminal title="Delete user (GDPR cascade)">cortex users delete user-123 --cascade</Terminal>
  </TabItem>
</Tabs>

<Callout type="info" title="Cross-Space Sharing">
  User profiles are shared across all memory spaces. Update preferences in one space, and they're available everywhere.
</Callout>

**Learn more:** [User Profiles Guide](/core-features/user-profiles)

---

## Context Chains

**Context chains** enable hierarchical context sharing in multi-agent systems and enable **cross-memorySpace** access with security controls.

<Callout type="tip" title="Think of Context Chains Like...">
  A management hierarchy where supervisors see their team's work, teams share knowledge within their context, and specialists can access supervisor context (limited). Everyone can access relevant historical context.
</Callout>

<Diagram title="Context Chain Visualization" caption="Hierarchical delegation across memory spaces">
{`flowchart TD
    RC[Root Context<br/>Supervisor Space<br/>'Handle customer refund request'] --> CC1[Child Context<br/>Finance Space<br/>'Process $500 refund']
    RC --> CC2[Child Context<br/>Customer Relations Space<br/>'Send apology email']`}
</Diagram>

<CodeBlock filename="context-chains.ts" language="typescript">
{`// Create parent context
const context = await cortex.contexts.create({
  purpose: "Handle customer refund request",
  memorySpaceId: "supervisor-space",
  userId: "user-123",
  metadata: { ticketId: "TICKET-456", priority: "high" },
});

// Supervisor delegates to finance agent (different memory space)
const financeContext = await cortex.contexts.create({
  purpose: "Process $500 refund",
  memorySpaceId: "finance-agent-space", // Different space!
  parentId: context.id, // Link to parent
  metadata: { amount: 500, reason: "defective product" },
});

// Finance agent accesses supervisor context (different space)
const fullContext = await cortex.contexts.get(financeContext.id, {
  includeChain: true,
  requestingSpace: "finance-agent-space",
});`}
</CodeBlock>

### Use Cases

<FeatureGrid columns={2}>
  <FeatureCard icon="ğŸ¢" title="Hierarchical Multi-Agent" description="Supervisor agents delegate to workers with shared context" />
  <FeatureCard icon="ğŸ“‹" title="Task Decomposition" description="Break complex tasks into subtasks while maintaining context" />
  <FeatureCard icon="ğŸ“" title="Audit Trails" description="Track full history of how tasks were handled across spaces" />
  <FeatureCard icon="ğŸ”" title="Secure Knowledge Sharing" description="Teams share context without exposing unrelated information" />
</FeatureGrid>

---

## Analytics

<Callout type="note" title="Cloud Mode Feature">
  Advanced analytics are planned for Cortex Cloud. Basic usage tracking will be available in both modes.
</Callout>

<CodeBlock filename="analytics.ts" language="typescript">
{`const stats = await cortex.analytics.getMemorySpaceStats("user-123-personal");

console.log(stats);
// {
//   totalMemories: 15432,
//   memoriesThisWeek: 234,
//   avgSearchTime: '23ms',
//   participants: ['cursor', 'claude', 'custom-bot'],
//   topTags: ['preferences', 'support', 'product-info'],
//   accessPatterns: {
//     mostAccessed: [{ id: 'mem_123', count: 45 }, ...],
//     leastAccessed: [{ id: 'mem_789', count: 1 }, ...],
//   },
//   importanceBreakdown: { high: 234, medium: 12043, low: 3155 }
// }`}
</CodeBlock>

<Tabs>
  <TabItem value="tracking" label="Access Tracking">
    ```typescript
    const memory = await cortex.memory.get("user-123-personal", "mem_123");

    console.log({
      accessCount: memory.accessCount,
      lastAccessed: memory.lastAccessed,
      createdAt: memory.createdAt,
    });
    ```
  </TabItem>
  <TabItem value="insights" label="Usage Insights">
    ```typescript
    // Find unused memories (potential cleanup)
    const unused = await cortex.analytics.findUnusedMemories("user-123-personal", {
      olderThan: "30d",
      maxAccessCount: 1,
    });

    // Find hot memories (frequently accessed)
    const hot = await cortex.analytics.findHotMemories("user-123-personal", {
      minAccessCount: 10,
      timeWindow: "7d",
    });
    ```
  </TabItem>
  <TabItem value="cli" label="CLI">
    <Terminal title="View database-wide statistics">cortex db stats</Terminal>
    <Terminal title="View space-specific statistics">cortex spaces stats user-123-personal</Terminal>
    <Terminal title="View memory statistics">cortex memory stats --space user-123-personal</Terminal>
  </TabItem>
</Tabs>

**Learn more:** [Access Analytics Guide](/core-features/access-analytics)

---

## Data Flow

### Complete Memory Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interaction                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Your Application                            â”‚
â”‚  â€¢ Generate embedding (your provider)                       â”‚
â”‚  â€¢ Call cortex.memory.remember()                            â”‚
â”‚  â€¢ Specify memorySpaceId                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Cortex Layer                              â”‚
â”‚  â€¢ Validate input                                           â”‚
â”‚  â€¢ Add metadata (timestamps, IDs)                           â”‚
â”‚  â€¢ Route to correct memory space                            â”‚
â”‚  â€¢ Store in Convex                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Convex Backend                             â”‚
â”‚  â€¢ ACID transaction                                         â”‚
â”‚  â€¢ Index embedding for vector search                        â”‚
â”‚  â€¢ Isolate by memorySpaceId                                 â”‚
â”‚  â€¢ Store in durable storage                                 â”‚
â”‚  â€¢ Trigger real-time updates                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Memory Available for Search                    â”‚
â”‚         (within memorySpaceId boundary)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Graph-Like Architecture

Cortex is built on a **document-oriented database** (Convex) but provides **graph-like querying** through references and relationships.

### Your Data IS a Graph

<FeatureGrid columns={3}>
  <FeatureCard icon="ğŸ“¦" title="Memory Spaces" description="Isolation boundaries" />
  <FeatureCard icon="ğŸ¤–" title="Participants" description="Agents/tools in a space" />
  <FeatureCard icon="ğŸ‘¤" title="Users" description="End users, customers" />
  <FeatureCard icon="ğŸ“‹" title="Contexts" description="Workflow tasks, hierarchies" />
  <FeatureCard icon="ğŸ’¬" title="Conversations" description="Message threads" />
  <FeatureCard icon="ğŸ§ " title="Memories" description="Knowledge entries" />
</FeatureGrid>

### Built-In Graph Traversals

<Tabs>
  <TabItem value="context" label="Context Chain Navigation">
    ```typescript
    const chain = await cortex.contexts.get(contextId, {
      includeChain: true, // â† Graph traversal!
    });

    console.log("Parent:", chain.parent.purpose); // 1-hop up
    console.log("Root:", chain.root.purpose); // N-hops to root
    console.log("Children:", chain.children.length); // 1-hop down
    ```
  </TabItem>
  <TabItem value="a2a" label="Memory Space Communication">
    ```typescript
    const conversation = await cortex.a2a.getConversation(
      "finance-agent",
      "hr-agent",
    );

    // Shows communication edges between memory spaces
    conversation.messages.forEach((msg) => {
      console.log(`${msg.from} â†’ ${msg.to}: ${msg.message}`);
    });
    ```
  </TabItem>
  <TabItem value="conversation" label="Conversation Tracing">
    ```typescript
    const memory = await cortex.memory.get("user-123-personal", memoryId, {
      includeConversation: true, // â† Follow conversationRef
    });

    console.log("Source conversation:", memory.conversation.conversationId);
    console.log("Source messages:", memory.sourceMessages);
    ```
  </TabItem>
</Tabs>

### Performance Characteristics

<ComparisonTable 
  headers={["Hops", "Query Type", "Latency", "Use Case"]}
  items={[
    { feature: "1-2", values: ["Direct relationships", "10-50ms", "Most queries"] },
    { feature: "3-5", values: ["Context hierarchies", "50-200ms", "Workflows, audit trails"] },
    { feature: "6+", values: ["Deep traversals (rare)", "200ms+", "Consider graph DB"] },
  ]}
/>

<Callout type="tip" title="When to Add a Graph Database">
  **Graph-Lite** (built-in) handles 90% of use cases. Add a native graph database when you need deep traversals (6+ hops), complex pattern matching, graph algorithms, or dense relationship networks.
</Callout>

**Learn more:** [Graph Capabilities](/advanced-topics/graph-capabilities)

---

## Common Patterns

<Accordion>
  <AccordionItem title="Pattern 1: Store on User Message (Hive Mode)" defaultOpen={true}>
    ```typescript
    const userMessage = req.body.message;
    const agentResponse = await generateResponse(userMessage);

    await cortex.memory.remember({
      memorySpaceId: "user-123-personal", // Shared space
      participantId: "cursor", // Which tool is storing
      conversationId: req.conversationId,
      userMessage,
      agentResponse,
      userId: req.user.id,
      userName: req.user.name,
      generateEmbedding: async (content) => await embed(content),
      importance: 50,
      tags: ["user-input"],
    });
    ```
  </AccordionItem>
  <AccordionItem title="Pattern 2: Search Before Response (Infinite Context)">
    ```typescript
    const memories = await cortex.memory.search("user-123-personal", userMessage, {
      embedding: await embed(userMessage),
      limit: 10,
    });

    const context = memories.map((m) => m.content).join("\n");
    const prompt = `
    Relevant Context:
    ${context}

    User: ${userMessage}
    Assistant:
    `;

    const response = await llm.complete(prompt);
    ```
  </AccordionItem>
  <AccordionItem title="Pattern 3: Cross-Space Collaboration">
    ```typescript
    await cortex.a2a.send({
      from: "finance-agent",
      to: "hr-agent",
      message: "Budget approved for hiring",
      importance: 85,
      metadata: { tags: ["approval", "hiring"] },
    });
    // Automatically stored in BOTH spaces (Collaboration Mode)

    const messages = await cortex.a2a.getConversation("hr-agent", "finance-agent");
    ```
  </AccordionItem>
  <AccordionItem title="Pattern 4: Hive Mode Coordination">
    ```typescript
    await cortex.memory.remember({
      memorySpaceId: "team-engineering",
      participantId: "code-reviewer-bot",
      conversationId: "internal-comm",
      userMessage: "[From deployment-bot] Build ready for review",
      agentResponse: "Starting code review",
      userId: "system",
      userName: "System",
      importance: 80,
      tags: ["coordination", "review"],
    });

    // Other participants see it immediately
    const updates = await cortex.memory.search("team-engineering", "code review", {
      limit: 5,
    });
    ```
  </AccordionItem>
</Accordion>

---

## Next Steps

<QuickNav>
  <QuickNavItem 
    title="Memory Spaces" 
    description="Deep dive into the isolation boundary" 
    href="/core-features/memory-spaces" 
  />
  <QuickNavItem 
    title="Configuration" 
    description="Set up deployments and environments" 
    href="/getting-started/configuration" 
  />
  <QuickNavItem 
    title="API Reference" 
    description="Complete API documentation" 
    href="/api-reference/overview" 
  />
  <QuickNavItem 
    title="Hive Mode Guide" 
    description="Master multi-tool memory sharing" 
    href="/core-features/hive-mode" 
  />
  <QuickNavItem 
    title="Infinite Context" 
    description="Never run out of context again" 
    href="/architecture/infinite-context" 
  />
  <QuickNavItem 
    title="Advanced Topics" 
    description="Graph queries, fact extraction, optimization" 
    href="/advanced-topics/graph-capabilities" 
  />
</QuickNav>

---

**Questions?** Ask in [Discussions](https://github.com/SaintNick1214/Project-Cortex/discussions).
