# Vercel AI SDK Integration

> **Package**: `@cortexmemory/vercel-ai-provider`  
> **Version**: 0.27.2  
> **SDK Compatibility**: Cortex SDK v0.21.0+  
> **Status**: âœ… Production Ready

Complete integration with Vercel AI SDK for Next.js applications with full memory orchestration capabilities.

## ðŸš€ Quickstart Demo (Recommended)

**The fastest way to get started** is with our interactive quickstart demo:

```bash
# Option 1: Run the demo from the monorepo
cd packages/vercel-ai-provider/quickstart
npm install && npm run dev

# Option 2: Use Cortex CLI to scaffold a new project
cortex init my-app --template vercel-ai-quickstart
cd my-app && cortex start
```

Open http://localhost:3000 to see:

- ðŸ”„ **Real-time Memory Orchestration** - Watch data flow through all 7 Cortex layers
- ðŸ“Š **Layer Flow Visualization** - Memory Space â†’ User â†’ Agent â†’ Conversation â†’ Vector â†’ Facts â†’ Graph
- ðŸ”€ **Memory Space Switching** - Live demonstration of multi-tenant isolation
- âš¡ **Streaming with Progressive Storage** - Real-time fact extraction during streaming
- ðŸ§¹ **Belief Revision** - See facts update when user changes their mind (SDK v0.24.0)

[ðŸ“– View Quickstart Documentation](https://github.com/SaintNick1214/Project-Cortex/tree/main/packages/vercel-ai-provider/quickstart)

---

## Documentation

- [Getting Started](./getting-started) - Step-by-step setup tutorial
- [API Reference](./api-reference) - Complete API documentation
- [Advanced Usage](./advanced-usage) - Graph memory, fact extraction, and custom configurations
- [Memory Spaces](./memory-spaces) - Multi-tenancy guide
- [Hive Mode](./hive-mode) - Cross-application memory sharing
- [Migration from mem0](./migration-from-mem0) - Switch from mem0
- [Troubleshooting](./troubleshooting) - Common issues and solutions

## Overview

The Cortex Memory Provider for Vercel AI SDK enables automatic persistent memory for AI applications built with Next.js and the Vercel AI SDK.

### Key Features

- ðŸ§  **Automatic Memory** - Retrieves context before responses, stores conversations after
- ðŸš€ **Zero Configuration** - Works out of the box with sensible defaults
- ðŸ“¦ **TypeScript Native** - Built for TypeScript from the ground up
- ðŸ”’ **Self-Hosted** - Deploy Convex anywhere, no API keys or vendor lock-in
- âš¡ **Edge Compatible** - Works in Vercel Edge Functions, Cloudflare Workers
- ðŸŽ¯ **Memory Spaces** - Isolate memory by user, team, or project
- ðŸ **Hive Mode** - Share memory across multiple agents/applications
- ðŸ“Š **ACID Guarantees** - Never lose data with Convex transactions
- ðŸ” **Semantic Search** - Find relevant memories with embeddings
- ðŸ§¬ **Fact Extraction** - LLM-powered fact extraction for 60-90% storage savings (SDK v0.18.0+)
- ðŸ•¸ï¸ **Graph Memory** - Optional Neo4j/Memgraph integration for relationship queries (SDK v0.19.0+)
- âš¡ **Enhanced Streaming** - Progressive storage, real-time hooks, and metrics
- ðŸ“Š **Layer Observation** - Real-time visualization of memory orchestration
- ðŸ§¹ **Belief Revision** - Intelligent fact updates when information changes (SDK v0.24.0+)

## Quick Start

### Installation

```bash
npm install @cortexmemory/vercel-ai-provider @cortexmemory/sdk ai convex
```

### Basic Example

```typescript
import { createCortexMemory } from "@cortexmemory/vercel-ai-provider";
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

const cortexMemory = createCortexMemory({
  convexUrl: process.env.CONVEX_URL!,
  memorySpaceId: "my-chatbot",
  userId: "user-123",
  userName: "User",

  // REQUIRED in SDK v0.17.0+
  agentId: "my-assistant",
  agentName: "My AI Assistant",

  // Optional: Enable graph memory (auto-configured via env vars)
  enableGraphMemory: process.env.CORTEX_GRAPH_SYNC === "true",

  // Optional: Enable fact extraction (auto-configured via env vars)
  enableFactExtraction: process.env.CORTEX_FACT_EXTRACTION === "true",

  // Optional: Enhanced streaming features
  streamingOptions: {
    storePartialResponse: true,
    progressiveFactExtraction: true,
    enableAdaptiveProcessing: true,
  },
});

const result = await streamText({
  model: cortexMemory(openai("gpt-4o-mini")),
  messages: [{ role: "user", content: "What did I tell you earlier?" }],
});
```

**That's it!** Memory is automatically orchestrated across all layers.

> âš ï¸ **Important:** Since SDK v0.17.0, `agentId` is required for all user-agent conversations. See [Breaking Changes](#breaking-changes) below.

## Key Capabilities

This integration provides:

1. **Memory-Augmented Models** - Wrap any AI SDK provider with memory
2. **Full Orchestration** - Automatic multi-layer memory storage:
   - Conversation storage (ACID-safe)
   - Vector embeddings (semantic search)
   - Fact extraction (structured knowledge)
   - Graph sync (entity relationships)
3. **Automatic Context Injection** - Relevant memories added to prompts
4. **Manual Control** - Search, remember, clear methods available
5. **Edge Runtime Support** - Works in serverless/edge environments
6. **Real-time Visualization** - Layer observer for UI integration

## Breaking Changes

### agentId Required (v0.17.0+)

Since SDK v0.17.0, all user-agent conversations **require an `agentId`**:

```typescript
// âŒ Old way (will throw error)
const cortexMemory = createCortexMemory({
  convexUrl: process.env.CONVEX_URL!,
  memorySpaceId: "my-chatbot",
  userId: "user-123",
});

// âœ… New way (v0.17.0+)
const cortexMemory = createCortexMemory({
  convexUrl: process.env.CONVEX_URL!,
  memorySpaceId: "my-chatbot",
  userId: "user-123",
  agentId: "my-assistant", // Required!
});
```

**Why?** Cortex properly tracks conversation participants for features like agent-to-agent memory sharing and proper attribution.

## Advanced Features

### Graph Memory (v0.19.0+)

Sync memories to Neo4j or Memgraph for relationship queries:

```typescript
const cortexMemory = createCortexMemory({
  // ... base config
  enableGraphMemory: true,

  // Auto-configured from env vars:
  // NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD
  // or MEMGRAPH_URI, MEMGRAPH_USERNAME, MEMGRAPH_PASSWORD
});
```

### Automatic Fact Extraction (v0.18.0+)

LLM-powered extraction of structured facts:

```typescript
const cortexMemory = createCortexMemory({
  // ... base config
  enableFactExtraction: true,

  // Auto-configured from env vars:
  // CORTEX_FACT_EXTRACTION=true
  // CORTEX_FACT_EXTRACTION_MODEL=gpt-4o-mini
});
```

### Layer Observation (for Visualization)

Watch data flow through all layers in real-time:

```typescript
const cortexMemory = createCortexMemory({
  // ... base config
  layerObserver: {
    onLayerUpdate: (event) => {
      // event.layer: 'memorySpace' | 'user' | 'agent' | 'conversation' | 'vector' | 'facts' | 'graph'
      // event.status: 'pending' | 'in_progress' | 'complete' | 'error'
      // event.latencyMs: number
      updateVisualization(event);
    },
    onOrchestrationComplete: (summary) => {
      console.log(`Total time: ${summary.totalLatencyMs}ms`);
    },
  },
});
```

### Enhanced Streaming

Progressive storage and real-time monitoring:

```typescript
const cortexMemory = createCortexMemory({
  // ... base config
  streamingOptions: {
    storePartialResponse: true,
    partialResponseInterval: 3000,
    progressiveFactExtraction: true,
    progressiveGraphSync: true,
    enableAdaptiveProcessing: true,
  },

  streamingHooks: {
    onChunk: (event) => console.log("Chunk:", event.chunk),
    onProgress: (event) => console.log("Progress:", event.bytesProcessed),
    onComplete: (event) => console.log("Done:", event.durationMs),
  },
});
```

## Environment Variables

Configure features via environment variables:

```bash
# Required
CONVEX_URL=https://your-project.convex.cloud
OPENAI_API_KEY=sk-...

# Fact Extraction (SDK v0.18.0+)
CORTEX_FACT_EXTRACTION=true
CORTEX_FACT_EXTRACTION_MODEL=gpt-4o-mini

# Graph Memory (SDK v0.19.0+)
CORTEX_GRAPH_SYNC=true
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password
```

## Environment Variables

Configure features via environment variables:

```bash
# Required
CONVEX_URL=https://your-project.convex.cloud
OPENAI_API_KEY=sk-...

# Fact Extraction (SDK v0.18.0+)
CORTEX_FACT_EXTRACTION=true
CORTEX_FACT_EXTRACTION_MODEL=gpt-4o-mini

# Graph Memory (SDK v0.19.0+)
CORTEX_GRAPH_SYNC=true
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password
```

## Package Source

- Package: [`packages/vercel-ai-provider/`](https://github.com/SaintNick1214/Project-Cortex/tree/main/packages/vercel-ai-provider)
- Quickstart Demo: [`packages/vercel-ai-provider/quickstart/`](https://github.com/SaintNick1214/Project-Cortex/tree/main/packages/vercel-ai-provider/quickstart)
- NPM: [@cortexmemory/vercel-ai-provider](https://www.npmjs.com/package/@cortexmemory/vercel-ai-provider)

## See Also

### Integration Guides

- [Getting Started](./getting-started) - Step-by-step tutorial
- [API Reference](./api-reference) - Complete API
- [Advanced Usage](./advanced-usage) - Graph, facts, custom configs
- [Troubleshooting](./troubleshooting) - Common issues

### Core Cortex Documentation

- [Memory Operations](../../03-api-reference/02-memory-operations) - remember() and rememberStream() API
- [Facts Operations](../../03-api-reference/12-facts-operations) - Fact extraction API
- [Graph Operations](../../03-api-reference/13-graph-operations) - Graph database integration
- [Memory Spaces](../../02-core-features/01-memory-spaces) - Multi-tenancy
- [Hive Mode](../../02-core-features/10-hive-mode) - Cross-application memory
